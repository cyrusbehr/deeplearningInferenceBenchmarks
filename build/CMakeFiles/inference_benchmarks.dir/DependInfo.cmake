# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  "CXX"
  )
# The set of files for implicit dependencies of each language:
set(CMAKE_DEPENDS_CHECK_CXX
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/inferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/inferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/inferenceManager.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/inferenceManager.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/main.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/main.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/mxnetInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/mxnetInferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/ncnnInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/ncnnInferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/onnxruntimeInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/onnxruntimeInferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/openVinoInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/openVinoInferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/tensorflowInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/tensorflowInferenceEngine.cpp.o"
  "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/src/tvmInferenceEngine.cpp" "/home/nchafni/Cyrus/benchmarks/inferenceSpeed/build/CMakeFiles/inference_benchmarks.dir/src/tvmInferenceEngine.cpp.o"
  )
set(CMAKE_CXX_COMPILER_ID "GNU")

# Preprocessor definitions for this target.
set(CMAKE_TARGET_DEFINITIONS_CXX
  "USE_OPENVINO=ON"
  )

# The include file search paths:
set(CMAKE_CXX_TARGET_INCLUDE_PATH
  "../3rd_party_libs/ncnn/build_broadwell/install/include/ncnn"
  "../3rd_party_libs/cxxopts/include"
  "../3rd_party_libs/tensorflow"
  "../3rd_party_libs/onnxruntime/include"
  "/opt/intel/openvino/deployment_tools/inference_engine/include"
  "/opt/intel/openvino/deployment_tools/inference_engine/samples/common"
  "../include"
  "/opt/intel/openvino_2019.3.376/opencv/include"
  )

# Targets to which this target links.
set(CMAKE_TARGET_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")
